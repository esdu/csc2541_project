{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blogs.mathworks.com/images/loren/2016/multiarmedbandit.jpg\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib; matplotlib.rcParams['figure.figsize'] = (15,3)\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload all packages - make debugging easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_DENSE_USERS_TO_TEST = 40\n",
    "N_DENSE_USERS_TO_ACTUALLY_TEST = 20\n",
    "\n",
    "N_STEPS_INITIAL_TRAIN = 2000\n",
    "N_STEPS_FINETUNE = 500\n",
    "\n",
    "MAX_NUMBER_OF_ITEMS = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from exp.utils import load_R, desparsify_2, prepare_test_users_sampled, remove_polarized_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = load_R()\n",
    "\n",
    "R = remove_polarized_ratings(R)\n",
    "# Remove the 3's\n",
    "R[R==3] = 0\n",
    "\n",
    "# # Subsample the 4's and 5's, so the sum of 4's and 5's are not the majority.\n",
    "# # This makes the chance that greedy picks something by luck be low.\n",
    "R[(R==4 | np.random.binomial(1,0.5,R.shape))] = 0\n",
    "\n",
    "# The point of this is to check that if we can fine-tune a model and still obtain meaningful uncertainty **updates** per user.\n",
    "# First, we pick a significant amount of users to check.\n",
    "dense_users, spars_users, _train_mask, _test_masks = \\\n",
    "    prepare_test_users_sampled(R, NUM_USERS_DENSE = N_DENSE_USERS_TO_TEST, NUM_USERS_SPARS = 0, PERC_DROP = 0, sample_range = 100, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(R>0)/R.shape[0]/R.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dense_users = dense_users[:N_DENSE_USERS_TO_ACTUALLY_TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_train_test_mask_for_user(user):\n",
    "    global train_mask\n",
    "    global test_masks\n",
    "    train_mask = np.copy(_train_mask)\n",
    "    train_mask[user,:] = 0\n",
    "    test_masks = {}\n",
    "    test_masks[user] = list((R>0)[user])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pmf import PMF\n",
    "model = PMF(ratingMatrix=R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_R(rhats, r=None, title=''):\n",
    "    _, n_items = rhats.shape\n",
    "    f, axes = plt.subplots(1, n_items, sharex=True, sharey=True)\n",
    "    i = 0\n",
    "    for j in range(n_items):\n",
    "        if r is not None:\n",
    "            axes[j].axvline(x=r[j], color='r', alpha=0.4)\n",
    "        axes[j].hist(rhats[:,j], histtype='stepfilled', normed=True, bins=100)\n",
    "    plt.xlim([0,6])\n",
    "    f.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "# Empirical Entropy of Ratings\n",
    "from empirical_entropy import empirical_entropy\n",
    "def get_entropy_data(model, user_index, intended_mask, num_samples=500):\n",
    "    samples = model.sample_for_user(user_index, num_samples)\n",
    "    _, per_item_entropy = empirical_entropy(samples)\n",
    "    mean_all_entropy = np.mean(per_item_entropy[np.where(R[user_index,:] > 0)]) # all items we could see\n",
    "    mean_intended_entropy = np.mean(per_item_entropy[np.where(intended_mask)]) # just elements we meant to test on\n",
    "    return mean_all_entropy, mean_intended_entropy\n",
    "\n",
    "# Latent Variable Entropy\n",
    "def joint_entropy(var):\n",
    "    marginal_entropy = 0.5*np.log(2*np.pi*np.e*var)\n",
    "    joint_entropy = np.sum(marginal_entropy, axis=1)\n",
    "    return joint_entropy\n",
    "    \n",
    "# Fetch user latent variables and return their entropy for PMF\n",
    "def get_user_latent_entropy_PMF(model, user):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    sess = model.sess\n",
    "    graph_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    U_var  = graph_vars[1]\n",
    "    U_entropy = joint_entropy(sess.run(tf.nn.softplus(U_var)))\n",
    "    \n",
    "    return U_entropy[user]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_checkpoint_fname_for_user(user):\n",
    "    return 'checkpoints/test_checkpoint_pmf_final_{}.ckpt'.format(user)\n",
    "\n",
    "# INITIAL_CHECKPOINT_FILE = 'checkpoints/initial_checkpoint.ckpt'\n",
    "# model.save(INITIAL_CHECKPOINT_FILE)\n",
    "for _, user in dense_users:\n",
    "    reset_train_test_mask_for_user(user)\n",
    "#     model.load(INITIAL_CHECKPOINT_FILE)\n",
    "    loss = model.train(train_mask, n_iter=N_STEPS_INITIAL_TRAIN)\n",
    "    model.save(get_checkpoint_fname_for_user(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mse_loss(posterior_samples, true_ratings):\n",
    "    return np.mean(np.square(np.mean(posterior_samples, axis=0) - true_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from banditChoice import BanditChoice\n",
    "bandit = BanditChoice()\n",
    "from banditChoiceTeoh import BanditChoiceTeoh\n",
    "banditT_0 = BanditChoiceTeoh(0.5)\n",
    "banditT_1 = BanditChoiceTeoh(1.0)\n",
    "banditT_2 = BanditChoiceTeoh(1.5)\n",
    "from banditChoiceUCBEmpirical import BanditChoiceUCBEmpirical\n",
    "banditE_0 = BanditChoiceUCBEmpirical(alpha=0.25)\n",
    "banditE_1 = BanditChoiceUCBEmpirical(alpha=0.5)\n",
    "\n",
    "\n",
    "def bandit_algo_random(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=1.0)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_exploit(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=0.0)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_thompson(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_thompson_sample(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_egreedy(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=0.1)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_ucb(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_ucb(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_teoh0(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = banditT_0.get_teoh_sample(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_teoh1(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = banditT_1.get_teoh_sample(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_teoh2(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = banditT_2.get_teoh_sample(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_ucb_e0(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = banditE_0.get_ucb_empirical(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_ucb_e1(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = banditE_1.get_ucb_empirical(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def test(users, bandit_algo, train=False, verbose=False):\n",
    "    regret_per_user = {}\n",
    "    mse_per_user = {}\n",
    "    entropy_per_user = {}\n",
    "    for _, user in users:\n",
    "        reset_train_test_mask_for_user(user)\n",
    "        checkpoint_name = get_checkpoint_fname_for_user(user)\n",
    "        \n",
    "        if verbose: print(\"---------------------- USER {} ----------------------\".format(user))\n",
    "\n",
    "        regret = []\n",
    "        mse = []\n",
    "        entropy = []\n",
    "        \n",
    "        mask_ = np.copy(train_mask)\n",
    "        test_mask_ = np.copy(test_masks[user])\n",
    "        n_items = np.sum(test_mask_)\n",
    "        \n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(min(n_items, MAX_NUMBER_OF_ITEMS)):\n",
    "            if train:\n",
    "                model.load(checkpoint_name)\n",
    "                l = model.train(mask_, n_iter=N_STEPS_FINETUNE)\n",
    "\n",
    "            # Bandit\n",
    "            samples = model.sample_for_user(user, 100)\n",
    "            item = bandit_algo(samples, test_mask_)\n",
    "                        \n",
    "            #MSE\n",
    "            avail = np.where(test_mask_)[0]\n",
    "            ratings = R[user][avail]\n",
    "            mse.append(mse_loss(samples[:,avail], ratings))\n",
    "\n",
    "            # Entropy\n",
    "            entropy.append(get_user_latent_entropy_PMF(model, user))\n",
    "            \n",
    "            # Regret\n",
    "            item_rating = R[user, item]\n",
    "            best_item_rating = np.max(R[user, :] * test_mask_)\n",
    "            regret.append(best_item_rating - item_rating)\n",
    "            \n",
    "            \n",
    "            # Retrain\n",
    "            mask_[user,item] = 1 # Showed this item; we can now train on it.\n",
    "            test_mask_[item] = 0 # Can't show this item anymore.\n",
    "\n",
    "        regret_per_user[user] = regret\n",
    "        mse_per_user[user] = mse\n",
    "        entropy_per_user[user] = entropy\n",
    "        \n",
    "    return regret_per_user, mse_per_user, entropy_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_inst_regret(regret_per_user):\n",
    "    for u_id, regret in regret_per_user.items():\n",
    "        plt.plot(regret)\n",
    "        plt.title(\"User {} regret over time\".format(u_id))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cum_regret(regret_per_user):\n",
    "    for u_id, regret in regret_per_user.items():\n",
    "        plt.plot(np.cumsum(regret))\n",
    "        plt.title(\"User {} cumulative regret over time\".format(u_id))\n",
    "    plt.show()\n",
    "        \n",
    "def get_regret_stats(regret_per_user):\n",
    "    if len(regret_per_user.items()) == 0:\n",
    "        return float('nan'), float('nan')\n",
    "    total_regret = sum([sum(regret) for _, regret in regret_per_user.items()])\n",
    "    avg_regret = total_regret / len(regret_per_user.items())\n",
    "    return total_regret, avg_regret\n",
    "\n",
    "def print_regret_stats(regret_per_user):\n",
    "    total_regret, avg_regret = get_regret_stats(regret_per_user)\n",
    "    print(\"Total regret: {}\".format(total_regret))\n",
    "    print(\"Avg: {}\".format(avg_regret))\n",
    "    \n",
    "def plot_entropy(entropy_per_user):\n",
    "    for u_id, entropy in entropy_per_user.items():\n",
    "        plt.plot(entropy)\n",
    "        plt.title(\"User {} entropy over time\".format(u_id))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _pickle \n",
    "def save_results(results, fname):\n",
    "    _pickle.dump(results, open(fname, 'wb'))\n",
    "    \n",
    "def load_results(fname):\n",
    "    return _pickle.load(open(fname, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time dense_random = test(dense_users, bandit_algo_random, train=True)\n",
    "save_results(dense_random, 'dense_random_final.pkl')\n",
    "%time dense_exploit = test(dense_users, bandit_algo_exploit, train=True)\n",
    "save_results(dense_exploit, 'dense_exploit_final.pkl')\n",
    "%time dense_thompson = test(dense_users, bandit_algo_thompson, train=True)\n",
    "save_results(dense_thompson, 'dense_thompson_final.pkl')\n",
    "%time dense_ucb   = test(dense_users, bandit_algo_ucb  , train=True)\n",
    "save_results(dense_ucb, 'dense_ucb_final.pkl')\n",
    "%time dense_teoh0    = test(dense_users, bandit_algo_teoh0   , train=True)\n",
    "save_results(dense_teoh0, 'dense_teoh0_final.pkl')\n",
    "%time dense_teoh1    = test(dense_users, bandit_algo_teoh1   , train=True)\n",
    "save_results(dense_teoh1, 'dense_teoh1_final.pkl')\n",
    "%time dense_teoh2    = test(dense_users, bandit_algo_teoh2   , train=True)\n",
    "save_results(dense_teoh2, 'dense_teoh2_final.pkl')\n",
    "%time dense_ucb_e0   = test(dense_users, bandit_algo_ucb_e0  , train=True)\n",
    "save_results(dense_ucb_e0, 'dense_ucb_e0_final.pkl')\n",
    "%time dense_ucb_e1   = test(dense_users, bandit_algo_ucb_e1  , train=True)\n",
    "save_results(dense_ucb_e1, 'dense_ucb_e1_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [dense_random, \n",
    "dense_exploit,\n",
    "dense_thompson,\n",
    "dense_ucb,\n",
    "dense_teoh0,\n",
    "dense_teoh1,\n",
    "dense_teoh2,\n",
    "dense_ucb_e0,\n",
    "dense_ucb_e1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_regret_stats(dense_random[0])\n",
    "print_regret_stats(dense_exploit[0])\n",
    "print_regret_stats(dense_thompson[0])\n",
    "print_regret_stats(dense_ucb[0])\n",
    "print_regret_stats(dense_teoh0[0])\n",
    "print_regret_stats(dense_teoh1[0])\n",
    "print_regret_stats(dense_teoh2[0])\n",
    "print_regret_stats(dense_ucb_e0[0])\n",
    "print_regret_stats(dense_ucb_e1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _, user in dense_users:\n",
    "    plt.plot(np.cumsum(dense_random[0][user]), label='random')\n",
    "    plt.plot(np.cumsum(dense_exploit[0][user]), label='exploit')\n",
    "    plt.plot(np.cumsum(dense_thompson[0][user]), label='thompson')\n",
    "    plt.plot(np.cumsum(dense_ucb[0][user]), label='ucb')\n",
    "    plt.plot(np.cumsum(dense_teoh0[0][user]), label='teoh0')\n",
    "    plt.plot(np.cumsum(dense_teoh1[0][user]), label='teoh1')\n",
    "    plt.plot(np.cumsum(dense_teoh2[0][user]), label='teoh2')\n",
    "    plt.plot(np.cumsum(dense_ucb_e0[0][user]), label='ucb_e0')\n",
    "    plt.plot(np.cumsum(dense_ucb_e1[0][user]), label='ucb_e1')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_results(results, 'final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot MSE change over time\n",
    "labels = ['random', 'explot', 'thompson', 'ucb', 'teoh0', 'teoh1', 'teoh2', 'ucb_e0', 'ucb_e1']\n",
    "for _,user in dense_users:\n",
    "    for i in range(len(results)):\n",
    "        plt.plot(results[i][1][user][0:], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot entropy change over time\n",
    "labels = ['random', 'explot', 'thompson', 'ucb', 'teoh0', 'teoh1', 'teoh2', 'ucb_e0', 'ucb_e1']\n",
    "for _,user in dense_users:\n",
    "    for i in range(len(results)):\n",
    "        plt.plot(results[i][2][user][0:], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
