{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blogs.mathworks.com/images/loren/2016/multiarmedbandit.jpg\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib; matplotlib.rcParams['figure.figsize'] = (15,3)\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reload all packages - make debugging easier\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from exp.utils import load_R, desparsify_2, prepare_test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R contains 100000 ratings\n",
      "Before desparsify: % of items:  0.0630466936422\n",
      "After desparsify: % of items:  0.373593572446\n",
      "Size:  (354, 353)\n"
     ]
    }
   ],
   "source": [
    "R = load_R()\n",
    "\n",
    "# One reason our model doesn't seem to work well may be due to the matrix being too sparse.\n",
    "R = desparsify_2(R)\n",
    "\n",
    "# The point of this is to check that if we can fine-tune a model and still obtain meaningful uncertainty **updates** per user.\n",
    "# First, we pick a significant amount of users to check.\n",
    "dense_users, spars_users, train_mask, test_masks = \\\n",
    "    prepare_test_users(R, NUM_USERS_DENSE = 20, NUM_USERS_SPARS = 20, PERC_DROP = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44730\n",
      "1955\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(np.sum(train_mask))\n",
    "print(np.sum([np.sum(m) for _, m in test_masks.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pmf import PMF\n",
    "model = PMF(ratingMatrix=R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_R(rhats, r=None, title=''):\n",
    "    _, n_items = rhats.shape\n",
    "    f, axes = plt.subplots(1, n_items, sharex=True, sharey=True)\n",
    "    i = 0\n",
    "    for j in range(n_items):\n",
    "        if r is not None:\n",
    "            axes[j].axvline(x=r[j], color='r', alpha=0.4)\n",
    "        axes[j].hist(rhats[:,j], histtype='stepfilled', normed=True, bins=100)\n",
    "    plt.xlim([0,6])\n",
    "    f.suptitle(title)\n",
    "    plt.show()\n",
    "    \n",
    "# Empirical Entropy of Ratings\n",
    "from empirical_entropy import empirical_entropy\n",
    "def get_entropy_data(model, user_index, intended_mask, num_samples=500):\n",
    "    samples = model.sample_for_user(user_index, num_samples)\n",
    "    _, per_item_entropy = empirical_entropy(samples)\n",
    "    mean_all_entropy = np.mean(per_item_entropy[np.where(R[user_index,:] > 0)]) # all items we could see\n",
    "    mean_intended_entropy = np.mean(per_item_entropy[np.where(intended_mask)]) # just elements we meant to test on\n",
    "    return mean_all_entropy, mean_intended_entropy\n",
    "\n",
    "# Latent Variable Entropy\n",
    "def joint_entropy(vars):\n",
    "    marginal_entropy = 0.5*np.log(2*np.pi*np.e*vars)\n",
    "    joint_entropy = np.sum(vars, axis=1)\n",
    "    return joint_entropy\n",
    "    \n",
    "# Fetch user latent variables and return their entropy for PMF\n",
    "def get_user_latent_entropy_PMF(model, user):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    sess = model.sess\n",
    "    graph_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    U_var  = graph_vars[1]\n",
    "    Up_var = graph_vars[3]\n",
    "\n",
    "    U_entropy = joint_entropy(sess.run(tf.nn.softplus(U_var)))\n",
    "    Up_entropy = joint_entropy(sess.run(tf.nn.softplus(Up_var)))\n",
    "    \n",
    "    return U_entropy[user], Up_entropy[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_STEPS_INITIAL_TRAIN = 1500\n",
    "N_STEPS_FINETUNE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 8.97 s, total: 46.7 s\n",
      "Wall time: 22.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_checkpoing_pmf1500.ckpt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOING_FILENAME = 'test_checkpoing_pmf1500.ckpt'\n",
    "\n",
    "%time loss = model.train(train_mask, n_iter=N_STEPS_INITIAL_TRAIN)\n",
    "model.save(CHECKPOING_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from banditChoice import BanditChoice\n",
    "bandit = BanditChoice()\n",
    "\n",
    "def bandit_algo_random(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=1.0)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_exploit(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=0.0)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_egreedy(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_egreedy(samples[:,_avail_idx], _avail_idx, epsilon=0.1)\n",
    "    return item\n",
    "\n",
    "def bandit_algo_ucb(samples, mask):\n",
    "    _avail_idx = np.where(mask)[0]\n",
    "    item = bandit.get_ucb(samples[:,_avail_idx], _avail_idx)\n",
    "    return item\n",
    "\n",
    "def test(users, bandit_algo, train=False, verbose=False):\n",
    "    regret_per_user = {}\n",
    "    for _, user in users:\n",
    "        if verbose: print(\"---------------------- USER {} ----------------------\".format(user))\n",
    "\n",
    "        regret = []\n",
    "\n",
    "        mask_ = np.copy(train_mask)\n",
    "        test_mask_ = np.copy(test_masks[user])\n",
    "        n_items = np.sum(test_mask_)\n",
    "\n",
    "        cnt = 0\n",
    "\n",
    "        for i in range(n_items):\n",
    "            cnt += 1\n",
    "\n",
    "            # Bandit\n",
    "            samples = model.sample_for_user(user, 100)\n",
    "            item = bandit_algo(samples, test_mask_)\n",
    "\n",
    "            # Regret\n",
    "            item_rating = R[user, item]\n",
    "            best_item_rating = np.max(R[user, :] * test_mask_)\n",
    "            regret.append(best_item_rating - item_rating)\n",
    "\n",
    "            # Retrain\n",
    "            mask_[user,item] = 1 # Showed this item; we can now train on it.\n",
    "            test_mask_[item] = 0 # Can't show this item anymore.\n",
    "            if train:\n",
    "                model.load(CHECKPOING_FILENAME)\n",
    "                model.train(mask_, n_iter=N_STEPS_FINETUNE)\n",
    "\n",
    "        regret_per_user[user] = regret\n",
    "    return regret_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_inst_regret(regret_per_user):\n",
    "    for u_id, regret in regret_per_user.items():\n",
    "        plt.plot(regret)\n",
    "        plt.title(\"User {} regret over time\".format(u_id))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cum_regret(regret_per_user):\n",
    "    for u_id, regret in regret_per_user.items():\n",
    "        plt.plot(np.cumsum(regret))\n",
    "        plt.title(\"User {} cumulative regret over time\".format(u_id))\n",
    "    plt.show()\n",
    "        \n",
    "def get_regret_stats(regret_per_user):\n",
    "    if len(regret_per_user.items()) == 0:\n",
    "        return float('nan'), float('nan')\n",
    "    total_regret = sum([sum(regret) for _, regret in regret_per_user.items()])\n",
    "    avg_regret = total_regret / len(regret_per_user.items())\n",
    "    return total_regret, avg_regret\n",
    "\n",
    "def print_regret_stats(regret_per_user):\n",
    "    total_regret, avg_regret = get_regret_stats(regret_per_user)\n",
    "    print(\"Total regret: {}\".format(total_regret))\n",
    "    print(\"Avg: {}\".format(avg_regret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 5.79 s, total: 2min 17s\n",
      "Wall time: 45.2 s\n",
      "CPU times: user 2min 12s, sys: 5.68 s, total: 2min 17s\n",
      "Wall time: 43.6 s\n",
      "CPU times: user 2min 11s, sys: 5.84 s, total: 2min 17s\n",
      "Wall time: 48.3 s\n",
      "CPU times: user 38 s, sys: 1.64 s, total: 39.6 s\n",
      "Wall time: 12.2 s\n",
      "CPU times: user 38.1 s, sys: 1.63 s, total: 39.7 s\n",
      "Wall time: 12.3 s\n",
      "CPU times: user 38.4 s, sys: 1.8 s, total: 40.2 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%time dense20egreedy = test(dense_users[:20], bandit_algo_egreedy)\n",
    "%time dense20random  = test(dense_users[:20], bandit_algo_random)\n",
    "%time dense20exploit = test(dense_users[:20], bandit_algo_exploit)\n",
    "%time spars20egreedy = test(spars_users[:20], bandit_algo_egreedy)\n",
    "%time spars20random  = test(spars_users[:20], bandit_algo_random)\n",
    "%time spars20exploit = test(spars_users[:20], bandit_algo_exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total regret: 1588.0\n",
      "Avg: 79.4\n",
      "Total regret: 1938.0\n",
      "Avg: 96.9\n",
      "Total regret: 1526.0\n",
      "Avg: 76.3\n",
      "Total regret: 366.0\n",
      "Avg: 18.3\n",
      "Total regret: 453.0\n",
      "Avg: 22.65\n",
      "Total regret: 350.0\n",
      "Avg: 17.5\n"
     ]
    }
   ],
   "source": [
    "print_regret_stats(dense20egreedy)\n",
    "print_regret_stats(dense20random)\n",
    "print_regret_stats(dense20exploit)\n",
    "print_regret_stats(spars20egreedy)\n",
    "print_regret_stats(spars20random)\n",
    "print_regret_stats(spars20exploit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are slightly random. It would be better to take more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 25\n",
    "\n",
    "exploit = []\n",
    "for _ in range(N_SAMPLES):\n",
    "    regret_per_user = test(spars_users[:20], bandit_algo_exploit)\n",
    "    total_regret, avg_regret = get_regret_stats(regret_per_user)\n",
    "    exploit.append(avg_regret)\n",
    "    \n",
    "random = []\n",
    "for _ in range(N_SAMPLES):\n",
    "    regret_per_user = test(spars_users[:20], bandit_algo_random)\n",
    "    total_regret, avg_regret = get_regret_stats(regret_per_user)\n",
    "    random.append(avg_regret)\n",
    "    \n",
    "egreedy = []\n",
    "for _ in range(N_SAMPLES):\n",
    "    regret_per_user = test(spars_users[:20], bandit_algo_egreedy)\n",
    "    total_regret, avg_regret = get_regret_stats(regret_per_user)\n",
    "    egreedy.append(avg_regret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2QAAADFCAYAAAA7QDEeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIEQyAAAAAAgEAIZAAAAAATy/wE37ZGYITEcrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108e33940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(exploit, histtype='step', label='exploit')\n",
    "plt.hist(random, histtype='step', label='random')\n",
    "plt.hist(egreedy, histtype='step', label='egreedy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
